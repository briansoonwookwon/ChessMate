{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006cc9ac-f42e-4b2b-9540-b8d12e0156ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../bedrock_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c244d1-25e9-4a01-9a2c-632897ce1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from src.KB_agent import create_knowledgebase_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2f9011c-2de1-4c90-9997-eb50327cfb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "kb = FAISS.load_local(\"../database/knowledge_base\", embeddings_model, allow_dangerous_deserialization=True)\n",
    "retriever = kb.as_retriever(search_kwargs={'k': 4})\n",
    "\n",
    "model = init_chat_model(\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "                      model_provider=\"bedrock_converse\",\n",
    "                      region_name=\"us-east-1\",\n",
    "                      client=bedrock_client)\n",
    "    \n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks on chess. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Be as descriptive as possible while still being \"\n",
    "    \"factual and coherent.\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(model, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9432d2b7-a523-49c9-9121-c5817bba028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/chess_questions.txt\") as f:\n",
    "    questions = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2aeaaac-da52-406c-a1e2-ae425d4a3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for q in questions:\n",
    "    results = rag_chain.invoke({\"input\": q})\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":q,\n",
    "            \"retrieved_contexts\":[doc.page_content for doc in results[\"context\"]],\n",
    "            \"response\":results[\"answer\"]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aece9052-c9df-485d-b784-bb00dab8b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f8dda2a-2b57-43e6-a88a-ea8b8fb02e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9303}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import Faithfulness\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"us.amazon.nova-pro-v1:0\",\n",
    ")\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=[Faithfulness()],llm=evaluator_llm)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec5894-6d53-45b1-a4ec-6aec805d0d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv env)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
